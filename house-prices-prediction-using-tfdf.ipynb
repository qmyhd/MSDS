{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30407,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Prices Prediction using TensorFlow Decision Forests","metadata":{"_uuid":"172bc3de-5fea-4bc7-8916-4515055a45ea","_cell_guid":"38d56cc5-a544-4076-ad1f-431d87422e3b","trusted":true,"collapsed":false,"id":"5v5mm4amQRrm","papermill":{"duration":0.010092,"end_time":"2023-03-07T06:21:39.774967","exception":false,"start_time":"2023-03-07T06:21:39.764875","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-03T23:59:19.244144Z","iopub.execute_input":"2024-11-03T23:59:19.244842Z","iopub.status.idle":"2024-11-03T23:59:19.250862Z","shell.execute_reply.started":"2024-11-03T23:59:19.244779Z","shell.execute_reply":"2024-11-03T23:59:19.249526Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"This notebook walks you through how to train a baseline Random Forest model using TensorFlow Decision Forests on the House Prices dataset made available for this competition.\n\nRoughly, the code will look as follows:\n\n```\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\n\ndataset = pd.read_csv(\"project/dataset.csv\")\ntf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n\nmodel = tfdf.keras.RandomForestModel()\nmodel.fit(tf_dataset)\n\nprint(model.summary())\n```\n\nDecision Forests are a family of tree-based models including Random Forests and Gradient Boosted Trees. They are the best place to start when working with tabular data, and will often outperform (or provide a strong baseline) before you begin experimenting with neural networks.","metadata":{"_uuid":"e283dbf0-2770-452c-9e59-f114b2925c35","_cell_guid":"baf33568-41e4-4e8b-a77c-c8d0a4e508f0","trusted":true,"collapsed":false,"id":"Z4eo3rH_MKbC","papermill":{"duration":0.00862,"end_time":"2023-03-07T06:21:39.792607","exception":false,"start_time":"2023-03-07T06:21:39.783987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-03T23:59:19.253378Z","iopub.execute_input":"2024-11-03T23:59:19.254759Z","iopub.status.idle":"2024-11-03T23:59:19.266333Z","shell.execute_reply.started":"2024-11-03T23:59:19.254697Z","shell.execute_reply":"2024-11-03T23:59:19.264142Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Import the library","metadata":{"_uuid":"14c7e9a7-0e41-460a-befc-09e50392d93e","_cell_guid":"c71de9a6-a8f3-4574-bb43-c4257477a1bf","trusted":true,"collapsed":false,"id":"FVOXAyXl3-fA","papermill":{"duration":0.008317,"end_time":"2023-03-07T06:21:39.809564","exception":false,"start_time":"2023-03-07T06:21:39.801247","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-01T04:44:31.751203Z","iopub.execute_input":"2024-11-01T04:44:31.752482Z","iopub.status.idle":"2024-11-01T04:44:31.757614Z","shell.execute_reply.started":"2024-11-01T04:44:31.752433Z","shell.execute_reply":"2024-11-01T04:44:31.756142Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\n\n# Comment this if the data visualisations doesn't work on your side\n%matplotlib inline","metadata":{"_uuid":"95d77feb-5cf1-48ba-bece-8617124f3638","_cell_guid":"6cadb617-0491-45a9-8705-d7bdedaa469c","trusted":true,"collapsed":false,"id":"IGmyjJJatzBZ","papermill":{"duration":8.300496,"end_time":"2023-03-07T06:21:48.118668","exception":false,"start_time":"2023-03-07T06:21:39.818172","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.112637Z","iopub.status.idle":"2024-11-08T21:04:42.113943Z","shell.execute_reply.started":"2024-11-08T21:04:42.113562Z","shell.execute_reply":"2024-11-08T21:04:42.113605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"TensorFlow v\" + tf.__version__)\nprint(\"TensorFlow Decision Forests v\" + tfdf.__version__)","metadata":{"_uuid":"f2b6aafb-6044-4f5a-91ba-9bbad5639706","_cell_guid":"6ad8c8f7-77c2-445a-b4b1-cc6d515c3fd1","trusted":true,"collapsed":false,"id":"dh4qwB4iN7Ue","papermill":{"duration":0.019012,"end_time":"2023-03-07T06:21:48.149058","exception":false,"start_time":"2023-03-07T06:21:48.130046","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.115778Z","iopub.status.idle":"2024-11-08T21:04:42.117162Z","shell.execute_reply.started":"2024-11-08T21:04:42.116790Z","shell.execute_reply":"2024-11-08T21:04:42.116831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"_uuid":"5608da8a-9c95-4404-add3-5bf360b96ebc","_cell_guid":"7474deae-8288-4052-ada5-dc8cedef3e9c","trusted":true,"collapsed":false,"id":"-3vxMmCPvqpf","papermill":{"duration":0.009922,"end_time":"2023-03-07T06:21:48.16945","exception":false,"start_time":"2023-03-07T06:21:48.159528","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_file_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\ndataset_df = pd.read_csv(train_file_path)\nprint(\"Full train dataset shape is {}\".format(dataset_df.shape))","metadata":{"_uuid":"45752e46-ad1f-4bad-8ab0-a9ff53f3beaa","_cell_guid":"f68d1527-e015-4f3a-b734-ef981c99604d","trusted":true,"collapsed":false,"id":"JVMPH_IDOBH2","papermill":{"duration":0.066785,"end_time":"2023-03-07T06:21:48.245226","exception":false,"start_time":"2023-03-07T06:21:48.178441","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.118975Z","iopub.status.idle":"2024-11-08T21:04:42.120512Z","shell.execute_reply.started":"2024-11-08T21:04:42.120156Z","shell.execute_reply":"2024-11-08T21:04:42.120194Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The data is composed of 81 columns and 1460 entries. We can see all 81 dimensions of our dataset by printing out the first 3 entries using the following code:","metadata":{"_uuid":"e9f29ce6-e4c6-4af9-8d2e-ea31f4a1f419","_cell_guid":"86471572-2b1a-4b2e-93c3-7b001895ba06","trusted":true,"collapsed":false,"papermill":{"duration":0.008651,"end_time":"2023-03-07T06:21:48.263024","exception":false,"start_time":"2023-03-07T06:21:48.254373","status":"completed"},"tags":[],"id":"mTnx8h9i416m","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"dataset_df.head(3)","metadata":{"_uuid":"853a895e-ef76-4508-a9d2-0deafc73f24a","_cell_guid":"676fb89d-3e85-41a6-aa70-019db6002c16","trusted":true,"collapsed":false,"papermill":{"duration":0.049873,"end_time":"2023-03-07T06:21:48.321938","exception":false,"start_time":"2023-03-07T06:21:48.272065","status":"completed"},"tags":[],"id":"kgbP5R6X416m","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.122010Z","iopub.status.idle":"2024-11-08T21:04:42.123306Z","shell.execute_reply.started":"2024-11-08T21:04:42.122962Z","shell.execute_reply":"2024-11-08T21:04:42.122999Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* There are 79 feature columns. Using these features your model has to predict the house sale price indicated by the label column named `SalePrice`.","metadata":{"_uuid":"3c6cbc3b-889b-457a-aba5-58893c2eab81","_cell_guid":"61ed3ceb-c0f6-4b4a-9937-d4769f01d481","trusted":true,"collapsed":false,"papermill":{"duration":0.009123,"end_time":"2023-03-07T06:21:48.340722","exception":false,"start_time":"2023-03-07T06:21:48.331599","status":"completed"},"tags":[],"id":"ulu8XdxO416n","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"We will drop the `Id` column as it is not necessary for model training.","metadata":{"_uuid":"1822d8d1-b3e4-494c-bb2d-415d8987bebf","_cell_guid":"0773d29c-185e-4df3-b1de-6b3368ebdd4e","trusted":true,"collapsed":false,"papermill":{"duration":0.009025,"end_time":"2023-03-07T06:21:48.359367","exception":false,"start_time":"2023-03-07T06:21:48.350342","status":"completed"},"tags":[],"id":"n82wWtvL416n","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"dataset_df = dataset_df.drop('Id', axis=1)\ndataset_df.head(3)","metadata":{"_uuid":"b7767311-0c9d-4616-aabd-fddc87553385","_cell_guid":"259efb84-7d22-480d-abd8-6279c72bfe37","trusted":true,"collapsed":false,"papermill":{"duration":0.043419,"end_time":"2023-03-07T06:21:48.412206","exception":false,"start_time":"2023-03-07T06:21:48.368787","status":"completed"},"tags":[],"id":"0lItmbYS416n","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.125101Z","iopub.status.idle":"2024-11-08T21:04:42.126471Z","shell.execute_reply.started":"2024-11-08T21:04:42.126094Z","shell.execute_reply":"2024-11-08T21:04:42.126134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can inspect the types of feature columns using the following code:","metadata":{"_uuid":"97a1ebac-a2b3-4b79-acc2-388a7aa08f1a","_cell_guid":"ba7b7969-405d-4594-aaed-59759acbba73","trusted":true,"collapsed":false,"papermill":{"duration":0.009883,"end_time":"2023-03-07T06:21:48.432601","exception":false,"start_time":"2023-03-07T06:21:48.422718","status":"completed"},"tags":[],"id":"QA_v408l416n","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"dataset_df.info()","metadata":{"_uuid":"7dae1d27-43ca-425f-8287-f674ec5520c1","_cell_guid":"58072f59-e858-4254-bbec-997ce86236a0","trusted":true,"collapsed":false,"papermill":{"duration":0.046783,"end_time":"2023-03-07T06:21:48.489619","exception":false,"start_time":"2023-03-07T06:21:48.442836","status":"completed"},"tags":[],"id":"du6DU4Of416n","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.128198Z","iopub.status.idle":"2024-11-08T21:04:42.129583Z","shell.execute_reply.started":"2024-11-08T21:04:42.129208Z","shell.execute_reply":"2024-11-08T21:04:42.129247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## House Price Distribution\n\nNow let us take a look at how the house prices are distributed.","metadata":{"_uuid":"1e390abf-d0ce-4403-9659-ea1e0d32bdbf","_cell_guid":"a6da0785-b3d8-41d9-9b86-caa0e6edeaa1","trusted":true,"collapsed":false,"papermill":{"duration":0.010252,"end_time":"2023-03-07T06:21:48.510224","exception":false,"start_time":"2023-03-07T06:21:48.499972","status":"completed"},"tags":[],"id":"PxdZCHvk416o","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(dataset_df['SalePrice'].describe())\nplt.figure(figsize=(9, 8))\nsns.histplot(dataset_df['SalePrice'], color='g', bins=100, kde=True)\n\nplt.show()","metadata":{"_uuid":"6ad92fd6-346c-4a69-9776-0f0732d0157b","_cell_guid":"8e7021f7-1e1b-42a0-9389-292b56e46edd","trusted":true,"collapsed":false,"papermill":{"duration":0.497946,"end_time":"2023-03-07T06:21:49.018361","exception":false,"start_time":"2023-03-07T06:21:48.520415","status":"completed"},"tags":[],"id":"qROZWZyE416o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.131362Z","iopub.status.idle":"2024-11-08T21:04:42.132725Z","shell.execute_reply.started":"2024-11-08T21:04:42.132364Z","shell.execute_reply":"2024-11-08T21:04:42.132406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Numerical data distribution\n\nWe will now take a look at how the numerical features are distributed. In order to do this, let us first list all the types of data from our dataset and select only the numerical ones.","metadata":{"_uuid":"a3e95ad7-6492-41c2-9399-52a75edbac12","_cell_guid":"91088f1c-80c3-44b2-ab63-0c5ec81411ca","trusted":true,"collapsed":false,"papermill":{"duration":0.01022,"end_time":"2023-03-07T06:21:49.039644","exception":false,"start_time":"2023-03-07T06:21:49.029424","status":"completed"},"tags":[],"id":"tKnn1nR-416o","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"list(set(dataset_df.dtypes.tolist()))","metadata":{"_uuid":"fb1daf44-f3a1-4ba2-b2e9-aceac2ae639c","_cell_guid":"bd12b654-5953-4bf3-8470-a71bca62a32f","trusted":true,"collapsed":false,"papermill":{"duration":0.022381,"end_time":"2023-03-07T06:21:49.0727","exception":false,"start_time":"2023-03-07T06:21:49.050319","status":"completed"},"tags":[],"id":"-hrMItSC416o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.134548Z","iopub.status.idle":"2024-11-08T21:04:42.135979Z","shell.execute_reply.started":"2024-11-08T21:04:42.135612Z","shell.execute_reply":"2024-11-08T21:04:42.135655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_num = dataset_df.select_dtypes(include = ['float64', 'int64'])\ndf_num.head()","metadata":{"_uuid":"0ce29260-71c9-40d4-a7de-0892e93fe92b","_cell_guid":"074b8a3f-fb74-4dc7-af55-ee91d705e1c3","trusted":true,"collapsed":false,"papermill":{"duration":0.038307,"end_time":"2023-03-07T06:21:49.122233","exception":false,"start_time":"2023-03-07T06:21:49.083926","status":"completed"},"tags":[],"id":"Vg2PQvfb416o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.137497Z","iopub.status.idle":"2024-11-08T21:04:42.138589Z","shell.execute_reply.started":"2024-11-08T21:04:42.138135Z","shell.execute_reply":"2024-11-08T21:04:42.138171Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let us plot the distribution for all the numerical features.","metadata":{"_uuid":"b902e96b-db4e-4aef-ad38-0c147fac3a68","_cell_guid":"3f33a17d-cab9-4984-9317-92ce412c1b12","trusted":true,"collapsed":false,"papermill":{"duration":0.0106,"end_time":"2023-03-07T06:21:49.144057","exception":false,"start_time":"2023-03-07T06:21:49.133457","status":"completed"},"tags":[],"id":"MnaH5h8u416o","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);","metadata":{"_uuid":"b6a58b92-3249-401f-bca4-d8ab03cee1e5","_cell_guid":"99ebe2c4-8b0b-4c2c-8c35-827c9efe2373","trusted":true,"collapsed":false,"papermill":{"duration":8.021473,"end_time":"2023-03-07T06:21:57.176534","exception":false,"start_time":"2023-03-07T06:21:49.155061","status":"completed"},"tags":[],"id":"Dj4h_dIw416o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.140469Z","iopub.status.idle":"2024-11-08T21:04:42.141877Z","shell.execute_reply.started":"2024-11-08T21:04:42.141480Z","shell.execute_reply":"2024-11-08T21:04:42.141523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare the dataset\n\nThis dataset contains a mix of numeric, categorical and missing features. TF-DF supports all these feature types natively, and no preprocessing is required. This is one advantage of tree-based models, making them a great entry point to Tensorflow and ML.","metadata":{"_uuid":"4004baac-5f05-4195-89f2-bbc164ee7750","_cell_guid":"09eeed58-ad29-4f97-8a94-19cde0907519","trusted":true,"collapsed":false,"id":"H4O7QCoh5e2e","papermill":{"duration":0.012325,"end_time":"2023-03-07T06:21:57.202216","exception":false,"start_time":"2023-03-07T06:21:57.189891","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Now let us split the dataset into training and testing datasets:","metadata":{"_uuid":"85cdd76a-9ac5-42ba-a315-13f633924c3e","_cell_guid":"8bd728d5-753e-4e6c-afe6-80eea2dcfbf9","trusted":true,"collapsed":false,"id":"brbRsBQfSC74","papermill":{"duration":0.012106,"end_time":"2023-03-07T06:21:57.227439","exception":false,"start_time":"2023-03-07T06:21:57.215333","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\n\ndef split_dataset(dataset, test_ratio=0.30):\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)\nprint(\"{} examples in training, {} examples in testing.\".format(\n    len(train_ds_pd), len(valid_ds_pd)))","metadata":{"_uuid":"890721d0-11b9-4478-bd15-5b3e920ee546","_cell_guid":"65aa20ff-8f08-4bbc-9892-74b6c0109cae","trusted":true,"collapsed":false,"id":"tsQad0t7SBv2","papermill":{"duration":0.025712,"end_time":"2023-03-07T06:21:57.266147","exception":false,"start_time":"2023-03-07T06:21:57.240435","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.144113Z","iopub.status.idle":"2024-11-08T21:04:42.144813Z","shell.execute_reply.started":"2024-11-08T21:04:42.144458Z","shell.execute_reply":"2024-11-08T21:04:42.144498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There's one more step required before we can train the model. We need to convert the datatset from Pandas format (`pd.DataFrame`) into TensorFlow Datasets format (`tf.data.Dataset`).\n\n[TensorFlow Datasets](https://www.tensorflow.org/datasets/overview) is a high performance data loading library which is helpful when training neural networks with accelerators like GPUs and TPUs.","metadata":{"_uuid":"0ebde487-069d-4efa-b0f6-ee5563fd53c7","_cell_guid":"00d62775-9fc6-4716-8d8f-9c72d04f2aa2","trusted":true,"collapsed":false,"id":"-hNGPbLlSGvp","papermill":{"duration":0.01598,"end_time":"2023-03-07T06:21:57.294832","exception":false,"start_time":"2023-03-07T06:21:57.278852","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"By default the Random Forest Model is configured to train classification tasks. Since this is a regression problem, we will specify the type of the task (`tfdf.keras.Task.REGRESSION`) as a parameter here.","metadata":{"_uuid":"5ad8429b-5929-49c1-b06a-4785db218329","_cell_guid":"95c5e1d4-496c-437d-a620-1a6f43acf200","trusted":true,"collapsed":false,"papermill":{"duration":0.012107,"end_time":"2023-03-07T06:21:57.319528","exception":false,"start_time":"2023-03-07T06:21:57.307421","status":"completed"},"tags":[],"id":"7goqxGx3416p","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"label = 'SalePrice'\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)","metadata":{"_uuid":"dc78e603-de20-4eea-adcd-00ed6ec895fa","_cell_guid":"898b7536-5082-45ce-a5e6-62fbdf5b44a0","trusted":true,"collapsed":false,"id":"xQgimfirSGQ9","papermill":{"duration":0.26438,"end_time":"2023-03-07T06:21:57.596711","exception":false,"start_time":"2023-03-07T06:21:57.332331","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.146805Z","iopub.status.idle":"2024-11-08T21:04:42.147523Z","shell.execute_reply.started":"2024-11-08T21:04:42.147154Z","shell.execute_reply":"2024-11-08T21:04:42.147196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Select a Model\n\nThere are several tree-based models for you to choose from.\n\n* RandomForestModel\n* GradientBoostedTreesModel\n* CartModel\n* DistributedGradientBoostedTreesModel\n\nTo start, we'll work with a Random Forest. This is the most well-known of the Decision Forest training algorithms.\n\nA Random Forest is a collection of decision trees, each trained independently on a random subset of the training dataset (sampled with replacement). The algorithm is unique in that it is robust to overfitting, and easy to use.","metadata":{"_uuid":"8d57111a-de30-4499-a914-909a33ee6230","_cell_guid":"9d839fc1-0e42-45c0-867d-a3009f0c059f","trusted":true,"collapsed":false,"id":"IUG4UKUyTNUu","papermill":{"duration":0.012451,"end_time":"2023-03-07T06:21:57.62217","exception":false,"start_time":"2023-03-07T06:21:57.609719","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"We can list the all the available models in TensorFlow Decision Forests using the following code:","metadata":{"_uuid":"e55bf44d-5c1b-41dd-98b2-71cf83dd1939","_cell_guid":"0834908a-4580-4b6b-9c3a-5e37b730ee1c","trusted":true,"collapsed":false,"papermill":{"duration":0.0125,"end_time":"2023-03-07T06:21:57.647596","exception":false,"start_time":"2023-03-07T06:21:57.635096","status":"completed"},"tags":[],"id":"VJSwNUdb416p","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"tfdf.keras.get_all_models()","metadata":{"_uuid":"78690b0c-74db-4f11-bba0-b10922bc2487","_cell_guid":"5333fdfd-4cfb-40b4-bc26-6d0598a6940c","trusted":true,"collapsed":false,"id":"MFmnkRR_Ui9w","papermill":{"duration":0.024872,"end_time":"2023-03-07T06:21:57.685403","exception":false,"start_time":"2023-03-07T06:21:57.660531","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.149382Z","iopub.status.idle":"2024-11-08T21:04:42.150694Z","shell.execute_reply.started":"2024-11-08T21:04:42.150333Z","shell.execute_reply":"2024-11-08T21:04:42.150376Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## How can I configure them?\n\nTensorFlow Decision Forests provides good defaults for you (e.g. the top ranking hyperparameters on our benchmarks, slightly modified to run in reasonable time). If you would like to configure the learning algorithm, you will find many options you can explore to get the highest possible accuracy.\n\nYou can select a template and/or set parameters as follows:\n\n```rf = tfdf.keras.RandomForestModel(hyperparameter_template=\"benchmark_rank1\", task=tfdf.keras.Task.REGRESSION)```\n\nRead more [here](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel).","metadata":{"_uuid":"5e51138d-123b-4692-9f85-0fbad084ed32","_cell_guid":"06acd4e1-b76b-47ea-90ba-f36b3dfba9b9","trusted":true,"collapsed":false,"id":"LiFn716FnMVQ","papermill":{"duration":0.012613,"end_time":"2023-03-07T06:21:57.710894","exception":false,"start_time":"2023-03-07T06:21:57.698281","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"","metadata":{"_uuid":"0e0701d8-4b99-4cfe-b19b-79524ade3225","_cell_guid":"ac350c18-a45b-436e-a1fa-0c63c74e513a","trusted":true,"collapsed":false,"id":"irxAS91IRVAX","papermill":{"duration":0.012674,"end_time":"2023-03-07T06:21:57.73704","exception":false,"start_time":"2023-03-07T06:21:57.724366","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Create a Random Forest\n\nToday, we will use the defaults to create the Random Forest Model while specifiyng the task type as `tfdf.keras.Task.REGRESSION`.","metadata":{"_uuid":"4520d2a8-a42f-422b-8897-6fa080a91308","_cell_guid":"f688ff88-4c60-481c-8730-bd02d8a8f01a","trusted":true,"collapsed":false,"id":"AUt4j8fLWRlR","papermill":{"duration":0.012522,"end_time":"2023-03-07T06:21:57.762516","exception":false,"start_time":"2023-03-07T06:21:57.749994","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"rf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nrf.compile(metrics=[\"mse\"]) # Optional, you can use this to include a list of eval metrics","metadata":{"_uuid":"ce00f1c6-1b10-4287-8909-3e85a061c0cf","_cell_guid":"5985acf2-cf9e-4f84-87bd-32363b90b2cb","trusted":true,"collapsed":false,"id":"O7bqOQMYTRXZ","papermill":{"duration":0.079382,"end_time":"2023-03-07T06:21:57.854964","exception":false,"start_time":"2023-03-07T06:21:57.775582","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.153188Z","iopub.status.idle":"2024-11-08T21:04:42.153903Z","shell.execute_reply.started":"2024-11-08T21:04:42.153534Z","shell.execute_reply":"2024-11-08T21:04:42.153577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train the model\n\nWe will train the model using a one-liner.\n\nNote: you may see a warning about Autograph. You can safely ignore this, it will be fixed in the next release.","metadata":{"_uuid":"8ad2360e-c0c8-4e3b-8e94-8363bad9b590","_cell_guid":"6fbd89db-9229-4a7f-9e89-48f188f8b7d1","trusted":true,"collapsed":false,"id":"0CzJ5_sh91Yt","papermill":{"duration":0.013391,"end_time":"2023-03-07T06:21:57.881539","exception":false,"start_time":"2023-03-07T06:21:57.868148","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"rf.fit(x=train_ds)","metadata":{"_uuid":"75f7c1aa-245d-43c4-aedf-2f74e13430d5","_cell_guid":"5101cd03-94c6-4585-8859-9d48c0591800","trusted":true,"collapsed":false,"id":"Ax6RircN92LW","papermill":{"duration":14.312048,"end_time":"2023-03-07T06:22:12.207321","exception":false,"start_time":"2023-03-07T06:21:57.895273","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.155884Z","iopub.status.idle":"2024-11-08T21:04:42.156573Z","shell.execute_reply.started":"2024-11-08T21:04:42.156207Z","shell.execute_reply":"2024-11-08T21:04:42.156244Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize the model\nOne benefit of tree-based models is that you can easily visualize them. The default number of trees used in the Random Forests is 300. We can select a tree to display below.","metadata":{"_uuid":"530179b3-77aa-4998-b49c-bbe39671bc7b","_cell_guid":"f7ee037d-224b-48d4-981d-3509d183e2f0","trusted":true,"collapsed":false,"id":"C1HJ6KxRT7IR","papermill":{"duration":0.014187,"end_time":"2023-03-07T06:22:12.236308","exception":false,"start_time":"2023-03-07T06:22:12.222121","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)","metadata":{"_uuid":"ffa16dc2-85d3-4729-acb5-2f3fac632664","_cell_guid":"9eb5cf1d-fe88-44fe-8d11-fb5ffa7d77fd","trusted":true,"collapsed":false,"id":"mTx73NgET9f8","papermill":{"duration":0.126324,"end_time":"2023-03-07T06:22:12.377534","exception":false,"start_time":"2023-03-07T06:22:12.25121","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.158770Z","iopub.status.idle":"2024-11-08T21:04:42.159455Z","shell.execute_reply.started":"2024-11-08T21:04:42.159095Z","shell.execute_reply":"2024-11-08T21:04:42.159134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate the model on the Out of bag (OOB) data and the validation dataset\n\nBefore training the dataset we have manually seperated 20% of the dataset for validation named as `valid_ds`.\n\nWe can also use Out of bag (OOB) score to validate our RandomForestModel.\nTo train a Random Forest Model, a set of random samples from training set are choosen by the algorithm and the rest of the samples are used to finetune the model.The subset of data that is not chosen is known as Out of bag data (OOB).\nOOB score is computed on the OOB data.\n\nRead more about OOB data [here](https://developers.google.com/machine-learning/decision-forests/out-of-bag).\n\nThe training logs show the Root Mean Squared Error (RMSE) evaluated on the out-of-bag dataset according to the number of trees in the model. Let us plot this.\n\nNote: Smaller values are better for this hyperparameter.","metadata":{"_uuid":"6e04bb4f-b211-4240-8bd6-4b41fe4b3f79","_cell_guid":"74434bd7-87eb-4125-bb07-76a7d1d84894","trusted":true,"collapsed":false,"id":"fazbJOgUT1n4","papermill":{"duration":0.015024,"end_time":"2023-03-07T06:22:12.407834","exception":false,"start_time":"2023-03-07T06:22:12.39281","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlogs = rf.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"RMSE (out-of-bag)\")\nplt.show()","metadata":{"_uuid":"91015c2a-acff-467a-819a-63374066e85e","_cell_guid":"dea539e7-fd3b-4cef-b6e9-0f0e8ea69a8d","trusted":true,"collapsed":false,"id":"ryddKoqLWrTp","papermill":{"duration":0.229991,"end_time":"2023-03-07T06:22:12.653052","exception":false,"start_time":"2023-03-07T06:22:12.423061","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.161342Z","iopub.status.idle":"2024-11-08T21:04:42.162017Z","shell.execute_reply.started":"2024-11-08T21:04:42.161662Z","shell.execute_reply":"2024-11-08T21:04:42.161699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also see some general stats on the OOB dataset:","metadata":{"_uuid":"28d4f53d-84c5-412e-ba67-ac7ee01f9263","_cell_guid":"43f37759-6ddc-4cb1-8af3-2be48df29ac6","trusted":true,"collapsed":false,"id":"Y-yMMsK5-3Mr","papermill":{"duration":0.015203,"end_time":"2023-03-07T06:22:12.684147","exception":false,"start_time":"2023-03-07T06:22:12.668944","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"inspector = rf.make_inspector()\ninspector.evaluation()","metadata":{"_uuid":"0bc5d1f4-21ab-4d3b-9a45-25dd4793738e","_cell_guid":"844345f7-aed7-4944-b0b6-392b435b2d6c","trusted":true,"collapsed":false,"id":"gdY8DvriTxky","papermill":{"duration":0.032483,"end_time":"2023-03-07T06:22:12.732339","exception":false,"start_time":"2023-03-07T06:22:12.699856","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.163696Z","iopub.status.idle":"2024-11-08T21:04:42.164411Z","shell.execute_reply.started":"2024-11-08T21:04:42.164037Z","shell.execute_reply":"2024-11-08T21:04:42.164076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, let us run an evaluation using the validation dataset.","metadata":{"_uuid":"fe7d8a9d-7444-4087-9c60-6ce30a87bf41","_cell_guid":"cdd8edb4-0e9e-40c5-b6ea-b6c9c7c8ecd3","trusted":true,"collapsed":false,"id":"GAoGJNjg-9sb","papermill":{"duration":0.015817,"end_time":"2023-03-07T06:22:12.764326","exception":false,"start_time":"2023-03-07T06:22:12.748509","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"evaluation = rf.evaluate(x=valid_ds,return_dict=True)\n\nfor name, value in evaluation.items():\n  print(f\"{name}: {value:.4f}\")","metadata":{"_uuid":"e3114364-e3d2-4a27-be2b-2f180951c113","_cell_guid":"a1655dcb-8fba-4bb3-adf5-e06276acff5d","trusted":true,"collapsed":false,"id":"39x97YqWZlgm","papermill":{"duration":1.513826,"end_time":"2023-03-07T06:22:14.294393","exception":false,"start_time":"2023-03-07T06:22:12.780567","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.165817Z","iopub.status.idle":"2024-11-08T21:04:42.166481Z","shell.execute_reply.started":"2024-11-08T21:04:42.166136Z","shell.execute_reply":"2024-11-08T21:04:42.166172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Variable importances\n\nVariable importances generally indicate how much a feature contributes to the model predictions or quality. There are several ways to identify important features using TensorFlow Decision Forests.\nLet us list the available `Variable Importances` for Decision Trees:","metadata":{"_uuid":"e25fe60a-5f25-4f52-8380-74813ce25d1f","_cell_guid":"d6a52743-89a3-4768-a781-e56ecd14935d","trusted":true,"collapsed":false,"id":"LWWqqDLM7WdZ","papermill":{"duration":0.015916,"end_time":"2023-03-07T06:22:14.32683","exception":false,"start_time":"2023-03-07T06:22:14.310914","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(f\"Available variable importances:\")\nfor importance in inspector.variable_importances().keys():\n  print(\"\\t\", importance)","metadata":{"_uuid":"0917d832-ea07-4c51-bac2-0857b4245669","_cell_guid":"aef52409-2ff4-4f28-adec-e2e45cc1ff06","trusted":true,"collapsed":false,"id":"xok16_jMgGZH","papermill":{"duration":0.028662,"end_time":"2023-03-07T06:22:14.371495","exception":false,"start_time":"2023-03-07T06:22:14.342833","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.168474Z","iopub.status.idle":"2024-11-08T21:04:42.169112Z","shell.execute_reply.started":"2024-11-08T21:04:42.168776Z","shell.execute_reply":"2024-11-08T21:04:42.168813Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As an example, let us display the important features for the Variable Importance `NUM_AS_ROOT`.\n\nThe larger the importance score for `NUM_AS_ROOT`, the more impact it has on the outcome of the model.\n\nBy default, the list is sorted from the most important to the least. From the output you can infer that the feature at the top of the list is used as the root node in most number of trees in the random forest than any other feature.","metadata":{"_uuid":"180b3fd5-be78-4c4a-a8f7-5502030e81ed","_cell_guid":"b30b025c-5a91-4e7f-9d0e-0f2492730821","trusted":true,"collapsed":false,"id":"USvNgqBR_JR2","papermill":{"duration":0.016135,"end_time":"2023-03-07T06:22:14.404154","exception":false,"start_time":"2023-03-07T06:22:14.388019","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"inspector.variable_importances()[\"NUM_AS_ROOT\"]","metadata":{"_uuid":"3a0c12fd-6e0c-484f-b97d-5417f7b30df3","_cell_guid":"e3f34591-be09-42b5-a5cf-51075edf469d","trusted":true,"collapsed":false,"id":"eI073gJHgHxr","papermill":{"duration":0.02844,"end_time":"2023-03-07T06:22:14.449021","exception":false,"start_time":"2023-03-07T06:22:14.420581","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.170984Z","iopub.status.idle":"2024-11-08T21:04:42.171670Z","shell.execute_reply.started":"2024-11-08T21:04:42.171280Z","shell.execute_reply":"2024-11-08T21:04:42.171344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plot the variable importances from the inspector using Matplotlib","metadata":{"_uuid":"b3d68404-926e-4af7-b9e4-0344affe6c0c","_cell_guid":"7a4dc6cb-e833-4117-bcde-0e953d30509b","trusted":true,"collapsed":false,"id":"qiASD3ei52H6","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\n\n# Mean decrease in AUC of the class 1 vs the others.\nvariable_importance_metric = \"NUM_AS_ROOT\"\nvariable_importances = inspector.variable_importances()[variable_importance_metric]\n\n# Extract the feature name and importance values.\n#\n# `variable_importances` is a list of <feature, importance> tuples.\nfeature_names = [vi[0].name for vi in variable_importances]\nfeature_importances = [vi[1] for vi in variable_importances]\n# The feature are ordered in decreasing importance value.\nfeature_ranks = range(len(feature_names))\n\nbar = plt.barh(feature_ranks, feature_importances, label=[str(x) for x in feature_ranks])\nplt.yticks(feature_ranks, feature_names)\nplt.gca().invert_yaxis()\n\n# TODO: Replace with \"plt.bar_label()\" when available.\n# Label each bar with values\nfor importance, patch in zip(feature_importances, bar.patches):\n  plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{importance:.4f}\", va=\"top\")\n\nplt.xlabel(variable_importance_metric)\nplt.title(\"NUM AS ROOT of the class 1 vs the others\")\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"37013fdc-b211-414d-97b8-b2e70bc75525","_cell_guid":"1d587645-71c1-4b44-873d-77bd59d8e015","trusted":true,"collapsed":false,"id":"cyyzelTl53AH","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.177905Z","iopub.status.idle":"2024-11-08T21:04:42.179811Z","shell.execute_reply.started":"2024-11-08T21:04:42.179417Z","shell.execute_reply":"2024-11-08T21:04:42.179466Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission\nFinally predict on the competition test data using the model.","metadata":{"_uuid":"beb4f598-e07f-4bb3-aee2-ab45caa65793","_cell_guid":"d117b99f-3624-4955-82a5-831f223f5a50","trusted":true,"collapsed":false,"papermill":{"duration":0.016075,"end_time":"2023-03-07T06:22:14.482026","exception":false,"start_time":"2023-03-07T06:22:14.465951","status":"completed"},"tags":[],"id":"jM9uB_7T416r","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"test_file_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\ntest_data = pd.read_csv(test_file_path)\nids = test_data.pop('Id')\n\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    test_data,\n    task = tfdf.keras.Task.REGRESSION)\n\npreds = rf.predict(test_ds)\noutput = pd.DataFrame({'Id': ids,\n                       'SalePrice': preds.squeeze()})\n\noutput.head()","metadata":{"_uuid":"32aa1816-4590-4853-ab45-72f775b854b3","_cell_guid":"7a6ae5da-8a9f-4ec5-90e9-e4035df5e96a","trusted":true,"collapsed":false,"papermill":{"duration":1.717453,"end_time":"2023-03-07T06:22:16.215717","exception":false,"start_time":"2023-03-07T06:22:14.498264","status":"completed"},"tags":[],"id":"gLySv9yJ416s","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.181127Z","iopub.status.idle":"2024-11-08T21:04:42.181819Z","shell.execute_reply.started":"2024-11-08T21:04:42.181476Z","shell.execute_reply":"2024-11-08T21:04:42.181514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"sample_submission_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\nsample_submission_df['SalePrice'] = rf.predict(test_ds)\nsample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\nsample_submission_df.head()","metadata":{"_uuid":"9d45c1fe-abf1-42ee-a068-7cdf2d40a692","_cell_guid":"eb5c649d-b9d8-4917-8edb-14de9db91a4e","trusted":true,"collapsed":false,"papermill":{"duration":0.839277,"end_time":"2023-03-07T06:22:17.072045","exception":false,"start_time":"2023-03-07T06:22:16.232768","status":"completed"},"tags":[],"id":"0wALPJtE416s","execution":{"iopub.status.busy":"2024-11-01T10:35:58.539811Z","iopub.execute_input":"2024-11-01T10:35:58.540447Z","iopub.status.idle":"2024-11-01T10:35:58.996025Z","shell.execute_reply.started":"2024-11-01T10:35:58.540389Z","shell.execute_reply":"2024-11-01T10:35:58.993976Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# **Homework 7 (DS6030) - Qais Youssef**","metadata":{"_uuid":"4e3246f1-2d66-47ae-bbce-2fb28f66ba01","_cell_guid":"5f4fe637-8532-4cb3-b189-181ff2a5a393","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"dataset_df = pd.read_csv(train_file_path)\n\n# Drop the 'Id' column\ndataset_df = dataset_df.drop('Id', axis=1)\n\n# Apply log transformation to the target variable to stabilize variance\ndataset_df['SalePrice'] = np.log1p(dataset_df['SalePrice'])\n\n\n# Feature Engineering\ndef create_new_features(df):\n    df = df.copy()\n    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n    df['Age'] = df['YrSold'] - df['YearBuilt']\n    df['TotalBath'] = (\n        df['FullBath'] + df['HalfBath'] * 0.5 +\n        df['BsmtFullBath'] + df['BsmtHalfBath'] * 0.5\n    )\n    return df\n\ndataset_df = create_new_features(dataset_df)\n\n\n# Split the dataset into training and validation sets\ntrain_ds_pd, valid_ds_pd = train_test_split(\n    dataset_df, test_size=0.3, random_state=seed)\nprint(f\"{len(train_ds_pd)} examples in training, {len(valid_ds_pd)} examples in validation.\")\n\n# Handle missing values\nnumerical_cols = train_ds_pd.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = train_ds_pd.select_dtypes(include=['object']).columns\n\n# Fill missing values\ntrain_ds_pd[numerical_cols] = train_ds_pd[numerical_cols].fillna(train_ds_pd[numerical_cols].mean())\nvalid_ds_pd[numerical_cols] = valid_ds_pd[numerical_cols].fillna(train_ds_pd[numerical_cols].mean())\n\ntrain_ds_pd[categorical_cols] = train_ds_pd[categorical_cols].fillna(train_ds_pd[categorical_cols].mode().iloc[0])\nvalid_ds_pd[categorical_cols] = valid_ds_pd[categorical_cols].fillna(train_ds_pd[categorical_cols].mode().iloc[0])\n\n\n# Convert the DataFrames to TensorFlow datasets\nlabel = 'SalePrice'\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    valid_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)","metadata":{"_uuid":"83adf27f-a52b-4123-ac32-f8c8afee6311","_cell_guid":"82c4aea4-f08c-4834-ad05-8e0b14ff93ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.185228Z","iopub.status.idle":"2024-11-08T21:04:42.186450Z","shell.execute_reply.started":"2024-11-08T21:04:42.186030Z","shell.execute_reply":"2024-11-08T21:04:42.186077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrain Random Forest with new hyperparameters\nrf_new = tfdf.keras.RandomForestModel(\n    task=tfdf.keras.Task.REGRESSION,\n    num_trees=500,\n    max_depth=8,    # Reduced from 12\n    min_examples=5  # Increased from 2\n)\nrf_new.compile(metrics=[\"mse\"])\nrf_new.fit(x=train_ds)\n\n# Evaluate the new Random Forest model\nevaluation_rf = rf_new.evaluate(x=valid_ds, return_dict=True)\nprint(\"\\nRandom Forest Evaluation on Validation Set:\")\nfor name, value in evaluation_rf.items():\n    print(f\"{name}: {value:.6f}\")\n\n# Define and train Gradient Boosted Trees model\ngbt_new = tfdf.keras.GradientBoostedTreesModel(\n    task=tfdf.keras.Task.REGRESSION,\n    num_trees=1500,\n    max_depth=6,\n    shrinkage=0.005,\n    subsample=0.9,\n    l2_regularization=3.0\n)\ngbt_new.compile(metrics=[\"mse\"])\ngbt_new.fit(x=train_ds)\n\n# Evaluate Gradient Boosted Trees model\nevaluation_gbt = gbt_new.evaluate(x=valid_ds, return_dict=True)\nprint(\"\\nGradient Boosted Trees Evaluation on Validation Set:\")\nfor name, value in evaluation_gbt.items():\n    print(f\"{name}: {value:.6f}\")","metadata":{"_uuid":"15487532-bcb5-41af-9f34-d704092aefd1","_cell_guid":"8d20199d-9117-48c6-9bd9-5e0c24f9ca6a","trusted":true,"collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.189158Z","iopub.status.idle":"2024-11-08T21:04:42.190812Z","shell.execute_reply.started":"2024-11-08T21:04:42.190421Z","shell.execute_reply":"2024-11-08T21:04:42.190469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the test dataset\ntest_file_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\ntest_data = pd.read_csv(test_file_path)\nids = test_data['Id']\ntest_data = test_data.drop('Id', axis=1)\n\ntest_data = create_new_features(test_data)\n\n# Handle missing values in the test set using training set statistics\nnumerical_cols = numerical_cols.drop('SalePrice', errors='ignore')  # Exclude target variable\ntest_data[numerical_cols] = test_data[numerical_cols].fillna(\n    train_ds_pd[numerical_cols].mean())\ntest_data[categorical_cols] = test_data[categorical_cols].fillna(\n    train_ds_pd[categorical_cols].mode().iloc[0])\n\n# Convert test data to TensorFlow dataset\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    test_data, task=tfdf.keras.Task.REGRESSION)\n\n# Generate predictions on test data\nrf_preds_log = rf_new.predict(test_ds).squeeze()\ngbt_preds_log = gbt_new.predict(test_ds).squeeze()\n","metadata":{"_uuid":"0a0eb3ea-200a-4acf-8d31-27e5b22596f2","_cell_guid":"68d5b839-dfaa-4f3f-8c91-95531f7743ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.192696Z","iopub.status.idle":"2024-11-08T21:04:42.194104Z","shell.execute_reply.started":"2024-11-08T21:04:42.193696Z","shell.execute_reply":"2024-11-08T21:04:42.193744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\ndef get_oof_predictions(model, X, y, folds=5):\n    from sklearn.model_selection import KFold\n    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n    oof_preds = np.zeros(len(X))\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train = y.iloc[train_index]\n\n        # Convert to TensorFlow datasets\n        train_ds_fold = tfdf.keras.pd_dataframe_to_tf_dataset(\n            X_train.assign(SalePrice=y_train), label='SalePrice', task=tfdf.keras.Task.REGRESSION)\n        val_ds_fold = tfdf.keras.pd_dataframe_to_tf_dataset(\n            X_val, task=tfdf.keras.Task.REGRESSION)\n\n        # Train model on fold\n        model.compile(metrics=[\"mse\"])\n        model.fit(x=train_ds_fold)\n\n        # Predict on validation fold\n        val_preds = model.predict(val_ds_fold).squeeze()\n        oof_preds[val_index] = val_preds\n\n    return oof_preds\n\n# Prepare data for meta-learner\nX = train_ds_pd.drop('SalePrice', axis=1)\ny = train_ds_pd['SalePrice']\n\n# Get OOF predictions for both models\nrf_oof_preds = get_oof_predictions(rf_new, X, y)\ngbt_oof_preds = get_oof_predictions(gbt_new, X, y)\n\n# Stack predictions\nmeta_X = np.vstack((rf_oof_preds, gbt_oof_preds)).T\nmeta_y = y.values\n\n# Train meta-learner\nmeta_learner = Ridge()\nmeta_learner.fit(meta_X, meta_y)\n\n# Prepare test predictions for meta-learner\nmeta_test_X = np.vstack((rf_preds_log, gbt_preds_log)).T\n\n# Predict with meta-learner\nfinal_preds_log = meta_learner.predict(meta_test_X)\nfinal_preds = np.expm1(final_preds_log)\n\n# Prepare submission\nsubmission = pd.DataFrame({'Id': ids, 'SalePrice': final_preds})\nsubmission.to_csv('submission_stacked.csv', index=False)\n\n# Preview the submission file\nprint(\"\\nStacked Model Submission Preview:\")\nprint(submission.head())","metadata":{"_uuid":"a40e0b44-5e7d-47c0-b401-78cd2e9e616c","_cell_guid":"e3f52f3b-ff83-4dc5-ac8e-99a1e108ae14","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-08T21:04:42.196255Z","iopub.status.idle":"2024-11-08T21:04:42.198098Z","shell.execute_reply.started":"2024-11-08T21:04:42.197704Z","shell.execute_reply":"2024-11-08T21:04:42.197750Z"}},"outputs":[],"execution_count":null}]}